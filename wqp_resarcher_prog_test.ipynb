{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# World Quant Predictive Researcher Prog Test\n",
    "\n",
    "## 1. Problem and data description\n",
    "In this challenge a series of corrupted words is given and the task is to retrieve their original state given a series of training tokens. There are explicit assumptions in the problem description and implicit ones too and it is important to consider them. \n",
    "\n",
    "The series was generated by breaking down sentences into separate tokens while removing all punctuations. This means that it is uncertain where a sentence starts or ends and where parts are separated by hyphen - common case is mentioning an example. With that being said the context of a token (the tokens before and after the current position) is somewhat unreliable and I am going to ignore it throughout this solution. Luckily the task relaxes the assumption that the casing of a token matters. Another assumption I will make is that hashmarks are reserved only to for corrupted tokens to signal missing characters.\n",
    "\n",
    "The task comes with a training data and a list of corrupted tokens, but there is no information given on their correct forms. Which means it is not possible to measure the efficiency of the model, unless I split the training data and separate some amount for testing - which I will transform by adding noise to it. I will use that to measure how many times the prediction equals to the original form. Usually it would be a good idea to do a cross validation of the model, but for the sake of simplicity I will not do that here.\n",
    "\n",
    "Given the above assumption of positional independence it is safe to store the series in a more compressed format than a list. First I will use a Counter object which storess key and their corresponding frequencies as values in an ordered form. It will make it easier to query the most and least common tokens in the data. Below I have created a function which loads a series of tokens, split it if needed and loads it into a new Counter object. I have also printed a couple of general observations about the data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The top 10 most common words in the vocabulary: [('the', 15989), ('and', 11439), ('of', 7835), ('a', 7479), ('to', 7132), ('i', 5278), ('it', 4947), ('in', 4845), ('that', 4203), ('was', 3878)]\nThe number of unique words in the training data: 17283\nTotal number of words in the training data: 284356\nThe number of unique words in the test data: 11904\nTotal number of words in the test data: 121867\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def read_data(path, ignore_hash=True, split=False):\n",
    "\n",
    "    tokens = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            t = line.strip().lower()\n",
    "            if ~ignore_hash & ('#' in t):\n",
    "                print(f'Warning: # in token {t}')\n",
    "            tokens.append(t)\n",
    "\n",
    "    if split:\n",
    "        train_data, test_data = train_test_split(tokens, train_size=0.7, test_size=0.3, shuffle=True)\n",
    "        train_data, test_data = Counter(train_data), Counter(test_data)\n",
    "        return train_data, test_data\n",
    "    \n",
    "    else:\n",
    "        tokens = Counter(tokens)\n",
    "        return tokens\n",
    "\n",
    "training_data, test_data = read_data('data/training_tokens.txt', ignore_hash=False, split=True)\n",
    "print(f'The top 10 most common words in the vocabulary: {training_data.most_common(10)}')\n",
    "print(f'The number of unique words in the training data: {len(training_data)}')\n",
    "print(f'Total number of words in the training data: {sum(v for _, v in training_data.items())}')\n",
    "print(f'The number of unique words in the test data: {len(test_data)}')\n",
    "print(f'Total number of words in the test data: {sum(v for _, v in test_data.items())}')"
   ]
  },
  {
   "source": [
    "First of all not surprisingly the most common words in the training data are function words, like the or and. This is very common in natural languages, because they are used to form and construct logic in sentences. The most common word is occurring 29% more than the second one which appears 30% more than the third. It looks almost as if there is an exponential decrease in frequency. This behaviour is a very common trait of the distribution of words of various natural languages. This observation will come handy later.\n",
    "\n",
    "## 2. Modeling\n",
    "The problem here is to find a string that matches the original form based on a noisy input. A common solution to this problem is to do a comparision between the noisy input and tokens in a corpus and then return the token with the smallest distance from the input. Usually the levenshtein distance is used as the notion of distance between two strings, which measures the number of deletions, insertions or replacements needed to transform a to b. This usually requires a lot of comparisions if the corpus is large or the search is not guided in some way. Luckily there are data structures that can facilitate this, for example Directed Acyclic Word Graphs. DAWGs combine vocabularys or corposes into a compressed format by breaking down words into characters and form a graph where words with similar patterns share the same path. So for example the words cat and mat would share the node a.\n",
    "\n",
    "Now given that the corrupted tokens are very noisy it can happen that the search would retrieve multiple suggestions. As I have mentioned earlier some words appear much more frequently that others so it would be reasonable to expect that exploiting this fact in the modeling process would be a good start. So the basic model will count the number of corruptions in the noisy input which will give a boundary for the similarity search in the dawg. Then matches are filtered based on length and then the token with the highest frequency in the training corpus is returned. If there are no matches then the model will return None."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from lexpy.dawg import DAWG # Directed Acyclic Word Graph\n",
    "\n",
    "def dawg_predictor(lexicon, token):\n",
    "\n",
    "    n_missing = token.count('#')\n",
    "    token = token.lower()\n",
    "    P = lexicon.search_within_distance(token, dist=n_missing)\n",
    "    P = [(p_i, training_data[p_i]) for p_i in P if len(token) == len(p_i)]\n",
    "\n",
    "    if P:\n",
    "        prediction = max(P, key=itemgetter(1))[0]\n",
    "    else:\n",
    "        prediction = None\n",
    "\n",
    "    return prediction\n",
    "\n",
    "\n",
    "lex = DAWG()\n",
    "lex.add_all([t for t in sorted(training_data.keys())])\n",
    "lex.reduce()"
   ]
  },
  {
   "source": [
    "## 3. Testing on corrupted tokens\n",
    "\n",
    "As I have mentioned above the real form of the corrupted tokens is not available, but it would be beneficial if there was a ways to understand the performance of the proposed solution. Earlier I have splitted the training data to separate some of it for testing purposes. However it is not clear how I should add noise to the test data to somewhat mimic the noise generation process. Therefore I will load the corrupted tokens with the function defined earlier to eyeball it to reproduce it later."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The top 10 most common words in the vocabulary: [('t#e', 1918), ('i#', 1660), ('a#d', 1310), ('o#', 1306), ('a', 906), ('t#', 609), ('t#a#', 456), ('a#', 440), ('t#e#', 399), ('w#s', 379)]\nThe 10 least common words in the vocabulary: [('w#r#d#', 1), ('b#g#i#e#', 1), ('w#s#e', 1), ('r#v#s#e#', 1), ('i#c#n#e', 1), ('e#e#t#a#', 1), ('p#r#a#e#c#', 1), ('m#s#e#y', 1), ('a#c#a#g#l', 1), ('k#e#s#k#', 1)]\nThe number of unique words in the vocabulary: 4324\nTotal number of words: 29293\n"
     ]
    }
   ],
   "source": [
    "corrupted_data = read_data('data/corrupted_tokens.txt', ignore_hash=True)\n",
    "print(f'The top 10 most common words in the vocabulary: {corrupted_data.most_common(10)}')\n",
    "print(f'The 10 least common words in the vocabulary: {corrupted_data.most_common()[-10:]}')\n",
    "print(f'The number of unique words in the vocabulary: {len(corrupted_data)}')\n",
    "print(f'Total number of words: {sum(v for _, v in corrupted_data.items())}')"
   ]
  },
  {
   "source": [
    "In the output above the first thing that the code printed was the top 10 most common corrupted tokens and then just below the 10 least common ones. First it seems like that hashmarks occur on every second position of a token, so I will make a method that will add noise to my test tokens in a similar fashion. Second it seems like that the distribution of the frequencies of the words have a tendency of decreasing sharply which is a similar observation to the one made earlier. It could be misleading though, because some characters are hidden and thus the same corrupted token could represent multiple real tokens.\n",
    "\n",
    "### 3.1 Accuracy on the test data\n",
    "\n",
    "Below I will define the noise generation function and I will use output of that to pass it to the model. The prediction of the model is then compared to the original token. I will measure the effectiveness of the proposed solution by comparing the sum of exact matches to the size of the test set - this is usually would be called accuracy the metric. I will look at two ways of calculating the accuracy. First I will compare the sum of the frequencies of the correctly predicted tokens to the sum of all the frequencies in the set. Then I will repeat this using only the count of correctly predicted tokens and comparing to the count of all the unique tokens in the test set. The first approach assumes that tokens appearing more frequently in the set have higher weight or importance. The second one assumes uniform weight for all tokens. The choice between them depends on the business requirement. More on that below."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original word: levenshtein, Result of adding noise: l#v#n#h#e#n\n",
      "Weighted Accuracy: 82.54%\n",
      "Unweighted Accuracy: 59.06%\n"
     ]
    }
   ],
   "source": [
    "def add_noise(token):\n",
    "\n",
    "    return ''.join(['#' if (j%2)==1 else c for j, c in enumerate(token)])\n",
    "\n",
    "test_word = \"levenshtein\"\n",
    "print(f'Original word: {test_word}, Result of adding noise: {add_noise(test_word)}')\n",
    "pred_scores = [f for t, f in test_data.items() if dawg_predictor(lex, add_noise(t)) == t]\n",
    "acc_w = sum(pred_scores) / sum(f for _, f in test_data.items())\n",
    "acc_u = len(pred_scores) / len(test_data)\n",
    "print(f'Weighted Accuracy: {acc_w*100:.2f}%')\n",
    "print(f'Unweighted Accuracy: {acc_u*100:.2f}%')"
   ]
  },
  {
   "source": [
    "First of all the result of the noise generation function given a test word seems to be doing its job. Exactly every second character has been changed to a hashmark.\n",
    "\n",
    "Second, it seems there is a notable difference between the weighted and unweighted accuracies on the test set. This is expected if we consider the earlier observation about the distribution of word frequencies. Because some words appear much more frequently than others then the correct prediction of some commonly appearing words are pushing the metric to appear better. It is important to mention that the model itself is biased to choose the words with the higher frequency. Now it is important to consider which reflects the final purpose better. The task does not specify, only asks \"to recover the corrupted tokens as best you can\". Now let's say I have a business which has a product that can process text and has a spellchecking capability. Would it be more important for my tool to recover the frequently appearing words or the rare ones?\n",
    "\n",
    "Now using the developed tool I can finally take a guess at the original form of the corrupted tokens. I will print the predictions of the top 15 most and least common tokens respectively.\n",
    "\n",
    "### 3.2 Recovery rate on corrupted tokens"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predictions for the top 15 most common corrupted tokens\ntoken: t#e, prediction: the\ntoken: i#, prediction: it\ntoken: a#d, prediction: and\ntoken: o#, prediction: of\ntoken: a, prediction: a\ntoken: t#, prediction: to\ntoken: t#a#, prediction: that\ntoken: a#, prediction: as\ntoken: t#e#, prediction: they\ntoken: w#s, prediction: was\ntoken: h#, prediction: he\ntoken: h#s, prediction: his\ntoken: i, prediction: i\ntoken: b#, prediction: by\ntoken: f#r, prediction: for\n"
     ]
    }
   ],
   "source": [
    "print('Predictions for the top 15 most common corrupted tokens')\n",
    "for tok, _ in corrupted_data.most_common(15):\n",
    "    pred = dawg_predictor(lex, tok)\n",
    "    print(f'token: {tok}, prediction: {pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predictions for the 15 least common corrupted tokens\n",
      "token: a#n#l#e#, prediction: None\n",
      "token: r#i#s, prediction: rails\n",
      "token: r#b#, prediction: ribs\n",
      "token: e#s#a#e#, prediction: None\n",
      "token: m#t#b#l#, prediction: None\n",
      "token: w#r#d#, prediction: worlds\n",
      "token: b#g#i#e#, prediction: beguiled\n",
      "token: w#s#e, prediction: waste\n",
      "token: r#v#s#e#, prediction: None\n",
      "token: i#c#n#e, prediction: None\n",
      "token: e#e#t#a#, prediction: None\n",
      "token: p#r#a#e#c#, prediction: permanency\n",
      "token: m#s#e#y, prediction: mystery\n",
      "token: a#c#a#g#l, prediction: archangel\n",
      "token: k#e#s#k#, prediction: None\n"
     ]
    }
   ],
   "source": [
    "print('Predictions for the 15 least common corrupted tokens')\n",
    "for tok, _ in corrupted_data.most_common()[-15:]:\n",
    "    pred = dawg_predictor(lex, tok)\n",
    "    print(f'token: {tok}, prediction: {pred}')"
   ]
  },
  {
   "source": [
    "Looking at the result of the predictions for the least common tokens in the vocabulary it seems there are some tokens that the model failed to recover. It would be interesting to see exactly how many times the model is returning None as a result. This way I can at least have a sense of how my model performs on the corrupted data. For this reason I have created a graph of the number of times the prediction was succesful (there was an answer from the model) compared to the case when it was not. Again I am comparing the results for the unique tokens versus the case of all tokens in the corpus."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Y = {t: dawg_predictor(lex, t) for t in corrupted_data}\n",
    "P = [f for t, f in corrupted_data.items() if Y[t] is not None]\n",
    "P_u = len(P) # number of unique recoveries\n",
    "P = sum(P) # total number of recoveries\n",
    "N = sum(v for _, v in corrupted_data.items()) # total number of tokens in the corrupted_tokens corpus\n",
    "N_u = len(corrupted_data) # number of unique corrupted tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total number of tokens: 29293\nTotal number of succesful recoveries: 28181\nUnique token count: 4324\nUnique tokens recovered: 3511\n"
     ]
    }
   ],
   "source": [
    "print(f'Total number of tokens: {N}')\n",
    "print(f'Total number of succesful recoveries: {P}')\n",
    "print(f'Unique token count: {N_u}')\n",
    "print(f'Unique tokens recovered: {P_u}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"285.518125pt\" version=\"1.1\" viewBox=\"0 0 424.790625 285.518125\" width=\"424.790625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-02-18T22:30:40.908854</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 285.518125 \nL 424.790625 285.518125 \nL 424.790625 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 59.690625 261.64 \nL 217.115625 261.64 \nL 217.115625 52.04 \nL 59.690625 52.04 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path clip-path=\"url(#p50935c875b)\" d=\"M 66.846307 261.64 \nL 130.452367 261.64 \nL 130.452367 62.020952 \nL 66.846307 62.020952 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path clip-path=\"url(#p50935c875b)\" d=\"M 146.353883 261.64 \nL 209.959943 261.64 \nL 209.959943 253.76319 \nL 146.353883 253.76319 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m63fae7121e\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"98.649337\" xlink:href=\"#m63fae7121e\" y=\"261.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- Found -->\n      <g transform=\"translate(83.383712 276.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 9.8125 72.90625 \nL 51.703125 72.90625 \nL 51.703125 64.59375 \nL 19.671875 64.59375 \nL 19.671875 43.109375 \nL 48.578125 43.109375 \nL 48.578125 34.8125 \nL 19.671875 34.8125 \nL 19.671875 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-70\"/>\n        <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n        <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n        <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n        <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-70\"/>\n       <use x=\"53.894531\" xlink:href=\"#DejaVuSans-111\"/>\n       <use x=\"115.076172\" xlink:href=\"#DejaVuSans-117\"/>\n       <use x=\"178.455078\" xlink:href=\"#DejaVuSans-110\"/>\n       <use x=\"241.833984\" xlink:href=\"#DejaVuSans-100\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"178.156913\" xlink:href=\"#m63fae7121e\" y=\"261.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- Not found -->\n      <g transform=\"translate(153.476444 276.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 9.8125 72.90625 \nL 23.09375 72.90625 \nL 55.421875 11.921875 \nL 55.421875 72.90625 \nL 64.984375 72.90625 \nL 64.984375 0 \nL 51.703125 0 \nL 19.390625 60.984375 \nL 19.390625 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-78\"/>\n        <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n        <path id=\"DejaVuSans-32\"/>\n        <path d=\"M 37.109375 75.984375 \nL 37.109375 68.5 \nL 28.515625 68.5 \nQ 23.6875 68.5 21.796875 66.546875 \nQ 19.921875 64.59375 19.921875 59.515625 \nL 19.921875 54.6875 \nL 34.71875 54.6875 \nL 34.71875 47.703125 \nL 19.921875 47.703125 \nL 19.921875 0 \nL 10.890625 0 \nL 10.890625 47.703125 \nL 2.296875 47.703125 \nL 2.296875 54.6875 \nL 10.890625 54.6875 \nL 10.890625 58.5 \nQ 10.890625 67.625 15.140625 71.796875 \nQ 19.390625 75.984375 28.609375 75.984375 \nz\n\" id=\"DejaVuSans-102\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-78\"/>\n       <use x=\"74.804688\" xlink:href=\"#DejaVuSans-111\"/>\n       <use x=\"135.986328\" xlink:href=\"#DejaVuSans-116\"/>\n       <use x=\"175.195312\" xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"206.982422\" xlink:href=\"#DejaVuSans-102\"/>\n       <use x=\"242.1875\" xlink:href=\"#DejaVuSans-111\"/>\n       <use x=\"303.369141\" xlink:href=\"#DejaVuSans-117\"/>\n       <use x=\"366.748047\" xlink:href=\"#DejaVuSans-110\"/>\n       <use x=\"430.126953\" xlink:href=\"#DejaVuSans-100\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_3\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"mac5294ec25\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"59.690625\" xlink:href=\"#mac5294ec25\" y=\"261.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 0 -->\n      <g transform=\"translate(46.328125 265.439219)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"59.690625\" xlink:href=\"#mac5294ec25\" y=\"226.222689\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 5000 -->\n      <g transform=\"translate(27.240625 230.021908)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"59.690625\" xlink:href=\"#mac5294ec25\" y=\"190.805378\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 10000 -->\n      <g transform=\"translate(20.878125 194.604597)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"59.690625\" xlink:href=\"#mac5294ec25\" y=\"155.388067\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 15000 -->\n      <g transform=\"translate(20.878125 159.187286)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"59.690625\" xlink:href=\"#mac5294ec25\" y=\"119.970756\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 20000 -->\n      <g transform=\"translate(20.878125 123.769975)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"59.690625\" xlink:href=\"#mac5294ec25\" y=\"84.553446\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 25000 -->\n      <g transform=\"translate(20.878125 88.352664)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_9\">\n     <!-- Count -->\n     <g transform=\"translate(14.798438 171.688437)rotate(-90)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 64.40625 67.28125 \nL 64.40625 56.890625 \nQ 59.421875 61.53125 53.78125 63.8125 \nQ 48.140625 66.109375 41.796875 66.109375 \nQ 29.296875 66.109375 22.65625 58.46875 \nQ 16.015625 50.828125 16.015625 36.375 \nQ 16.015625 21.96875 22.65625 14.328125 \nQ 29.296875 6.6875 41.796875 6.6875 \nQ 48.140625 6.6875 53.78125 8.984375 \nQ 59.421875 11.28125 64.40625 15.921875 \nL 64.40625 5.609375 \nQ 59.234375 2.09375 53.4375 0.328125 \nQ 47.65625 -1.421875 41.21875 -1.421875 \nQ 24.65625 -1.421875 15.125 8.703125 \nQ 5.609375 18.84375 5.609375 36.375 \nQ 5.609375 53.953125 15.125 64.078125 \nQ 24.65625 74.21875 41.21875 74.21875 \nQ 47.75 74.21875 53.53125 72.484375 \nQ 59.328125 70.75 64.40625 67.28125 \nz\n\" id=\"DejaVuSans-67\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-67\"/>\n      <use x=\"69.824219\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"131.005859\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"194.384766\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"257.763672\" xlink:href=\"#DejaVuSans-116\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 59.690625 261.64 \nL 59.690625 52.04 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 217.115625 261.64 \nL 217.115625 52.04 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path d=\"M 59.690625 261.64 \nL 217.115625 261.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path d=\"M 59.690625 52.04 \nL 217.115625 52.04 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_10\">\n    <!-- All tokens (N=29293) -->\n    <g transform=\"translate(73.965 46.04)scale(0.12 -0.12)\">\n     <defs>\n      <path d=\"M 34.1875 63.1875 \nL 20.796875 26.90625 \nL 47.609375 26.90625 \nz\nM 28.609375 72.90625 \nL 39.796875 72.90625 \nL 67.578125 0 \nL 57.328125 0 \nL 50.6875 18.703125 \nL 17.828125 18.703125 \nL 11.1875 0 \nL 0.78125 0 \nz\n\" id=\"DejaVuSans-65\"/>\n      <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n      <path d=\"M 9.078125 75.984375 \nL 18.109375 75.984375 \nL 18.109375 31.109375 \nL 44.921875 54.6875 \nL 56.390625 54.6875 \nL 27.390625 29.109375 \nL 57.625 0 \nL 45.90625 0 \nL 18.109375 26.703125 \nL 18.109375 0 \nL 9.078125 0 \nz\n\" id=\"DejaVuSans-107\"/>\n      <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n      <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n      <path d=\"M 31 75.875 \nQ 24.46875 64.65625 21.28125 53.65625 \nQ 18.109375 42.671875 18.109375 31.390625 \nQ 18.109375 20.125 21.3125 9.0625 \nQ 24.515625 -2 31 -13.1875 \nL 23.1875 -13.1875 \nQ 15.875 -1.703125 12.234375 9.375 \nQ 8.59375 20.453125 8.59375 31.390625 \nQ 8.59375 42.28125 12.203125 53.3125 \nQ 15.828125 64.359375 23.1875 75.875 \nz\n\" id=\"DejaVuSans-40\"/>\n      <path d=\"M 10.59375 45.40625 \nL 73.1875 45.40625 \nL 73.1875 37.203125 \nL 10.59375 37.203125 \nz\nM 10.59375 25.484375 \nL 73.1875 25.484375 \nL 73.1875 17.1875 \nL 10.59375 17.1875 \nz\n\" id=\"DejaVuSans-61\"/>\n      <path d=\"M 10.984375 1.515625 \nL 10.984375 10.5 \nQ 14.703125 8.734375 18.5 7.8125 \nQ 22.3125 6.890625 25.984375 6.890625 \nQ 35.75 6.890625 40.890625 13.453125 \nQ 46.046875 20.015625 46.78125 33.40625 \nQ 43.953125 29.203125 39.59375 26.953125 \nQ 35.25 24.703125 29.984375 24.703125 \nQ 19.046875 24.703125 12.671875 31.3125 \nQ 6.296875 37.9375 6.296875 49.421875 \nQ 6.296875 60.640625 12.9375 67.421875 \nQ 19.578125 74.21875 30.609375 74.21875 \nQ 43.265625 74.21875 49.921875 64.515625 \nQ 56.59375 54.828125 56.59375 36.375 \nQ 56.59375 19.140625 48.40625 8.859375 \nQ 40.234375 -1.421875 26.421875 -1.421875 \nQ 22.703125 -1.421875 18.890625 -0.6875 \nQ 15.09375 0.046875 10.984375 1.515625 \nz\nM 30.609375 32.421875 \nQ 37.25 32.421875 41.125 36.953125 \nQ 45.015625 41.5 45.015625 49.421875 \nQ 45.015625 57.28125 41.125 61.84375 \nQ 37.25 66.40625 30.609375 66.40625 \nQ 23.96875 66.40625 20.09375 61.84375 \nQ 16.21875 57.28125 16.21875 49.421875 \nQ 16.21875 41.5 20.09375 36.953125 \nQ 23.96875 32.421875 30.609375 32.421875 \nz\n\" id=\"DejaVuSans-57\"/>\n      <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      <path d=\"M 8.015625 75.875 \nL 15.828125 75.875 \nQ 23.140625 64.359375 26.78125 53.3125 \nQ 30.421875 42.28125 30.421875 31.390625 \nQ 30.421875 20.453125 26.78125 9.375 \nQ 23.140625 -1.703125 15.828125 -13.1875 \nL 8.015625 -13.1875 \nQ 14.5 -2 17.703125 9.0625 \nQ 20.90625 20.125 20.90625 31.390625 \nQ 20.90625 42.671875 17.703125 53.65625 \nQ 14.5 64.65625 8.015625 75.875 \nz\n\" id=\"DejaVuSans-41\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-65\"/>\n     <use x=\"68.408203\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"96.191406\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"123.974609\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"155.761719\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"194.970703\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"256.152344\" xlink:href=\"#DejaVuSans-107\"/>\n     <use x=\"310.4375\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"371.960938\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"435.339844\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"487.439453\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"519.226562\" xlink:href=\"#DejaVuSans-40\"/>\n     <use x=\"558.240234\" xlink:href=\"#DejaVuSans-78\"/>\n     <use x=\"633.044922\" xlink:href=\"#DejaVuSans-61\"/>\n     <use x=\"716.833984\" xlink:href=\"#DejaVuSans-50\"/>\n     <use x=\"780.457031\" xlink:href=\"#DejaVuSans-57\"/>\n     <use x=\"844.080078\" xlink:href=\"#DejaVuSans-50\"/>\n     <use x=\"907.703125\" xlink:href=\"#DejaVuSans-57\"/>\n     <use x=\"971.326172\" xlink:href=\"#DejaVuSans-51\"/>\n     <use x=\"1034.949219\" xlink:href=\"#DejaVuSans-41\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_9\">\n    <path d=\"M 260.165625 261.64 \nL 417.590625 261.64 \nL 417.590625 52.04 \nL 260.165625 52.04 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path clip-path=\"url(#pc63afe51bc)\" d=\"M 267.321307 261.64 \nL 330.927367 261.64 \nL 330.927367 62.020952 \nL 267.321307 62.020952 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path clip-path=\"url(#pc63afe51bc)\" d=\"M 346.828883 261.64 \nL 410.434943 261.64 \nL 410.434943 215.41662 \nL 346.828883 215.41662 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"matplotlib.axis_3\">\n    <g id=\"xtick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"299.124337\" xlink:href=\"#m63fae7121e\" y=\"261.64\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- Found -->\n      <g transform=\"translate(283.858712 276.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-70\"/>\n       <use x=\"53.894531\" xlink:href=\"#DejaVuSans-111\"/>\n       <use x=\"115.076172\" xlink:href=\"#DejaVuSans-117\"/>\n       <use x=\"178.455078\" xlink:href=\"#DejaVuSans-110\"/>\n       <use x=\"241.833984\" xlink:href=\"#DejaVuSans-100\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"378.631913\" xlink:href=\"#m63fae7121e\" y=\"261.64\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- Not found -->\n      <g transform=\"translate(353.951444 276.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-78\"/>\n       <use x=\"74.804688\" xlink:href=\"#DejaVuSans-111\"/>\n       <use x=\"135.986328\" xlink:href=\"#DejaVuSans-116\"/>\n       <use x=\"175.195312\" xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"206.982422\" xlink:href=\"#DejaVuSans-102\"/>\n       <use x=\"242.1875\" xlink:href=\"#DejaVuSans-111\"/>\n       <use x=\"303.369141\" xlink:href=\"#DejaVuSans-117\"/>\n       <use x=\"366.748047\" xlink:href=\"#DejaVuSans-110\"/>\n       <use x=\"430.126953\" xlink:href=\"#DejaVuSans-100\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_4\">\n    <g id=\"ytick_7\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"260.165625\" xlink:href=\"#mac5294ec25\" y=\"261.64\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0 -->\n      <g transform=\"translate(246.803125 265.439219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"260.165625\" xlink:href=\"#mac5294ec25\" y=\"233.212337\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 500 -->\n      <g transform=\"translate(234.078125 237.011556)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"260.165625\" xlink:href=\"#mac5294ec25\" y=\"204.784675\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 1000 -->\n      <g transform=\"translate(227.715625 208.583893)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_10\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"260.165625\" xlink:href=\"#mac5294ec25\" y=\"176.357012\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 1500 -->\n      <g transform=\"translate(227.715625 180.156231)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_11\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"260.165625\" xlink:href=\"#mac5294ec25\" y=\"147.929349\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 2000 -->\n      <g transform=\"translate(227.715625 151.728568)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_12\">\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"260.165625\" xlink:href=\"#mac5294ec25\" y=\"119.501686\"/>\n      </g>\n     </g>\n     <g id=\"text_18\">\n      <!-- 2500 -->\n      <g transform=\"translate(227.715625 123.300905)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_13\">\n     <g id=\"line2d_17\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"260.165625\" xlink:href=\"#mac5294ec25\" y=\"91.074024\"/>\n      </g>\n     </g>\n     <g id=\"text_19\">\n      <!-- 3000 -->\n      <g transform=\"translate(227.715625 94.873242)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_14\">\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"260.165625\" xlink:href=\"#mac5294ec25\" y=\"62.646361\"/>\n      </g>\n     </g>\n     <g id=\"text_20\">\n      <!-- 3500 -->\n      <g transform=\"translate(227.715625 66.44558)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_12\">\n    <path d=\"M 260.165625 261.64 \nL 260.165625 52.04 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_13\">\n    <path d=\"M 417.590625 261.64 \nL 417.590625 52.04 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path d=\"M 260.165625 261.64 \nL 417.590625 261.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path d=\"M 260.165625 52.04 \nL 417.590625 52.04 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_21\">\n    <!-- Unique tokens (N=4324) -->\n    <g transform=\"translate(264.531562 46.04)scale(0.12 -0.12)\">\n     <defs>\n      <path d=\"M 8.6875 72.90625 \nL 18.609375 72.90625 \nL 18.609375 28.609375 \nQ 18.609375 16.890625 22.84375 11.734375 \nQ 27.09375 6.59375 36.625 6.59375 \nQ 46.09375 6.59375 50.34375 11.734375 \nQ 54.59375 16.890625 54.59375 28.609375 \nL 54.59375 72.90625 \nL 64.5 72.90625 \nL 64.5 27.390625 \nQ 64.5 13.140625 57.4375 5.859375 \nQ 50.390625 -1.421875 36.625 -1.421875 \nQ 22.796875 -1.421875 15.734375 5.859375 \nQ 8.6875 13.140625 8.6875 27.390625 \nz\n\" id=\"DejaVuSans-85\"/>\n      <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n      <path d=\"M 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\nM 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nL 45.40625 54.6875 \nL 54.390625 54.6875 \nL 54.390625 -20.796875 \nL 45.40625 -20.796875 \nz\n\" id=\"DejaVuSans-113\"/>\n      <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-85\"/>\n     <use x=\"73.193359\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"136.572266\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"164.355469\" xlink:href=\"#DejaVuSans-113\"/>\n     <use x=\"227.832031\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"291.210938\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"352.734375\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"384.521484\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"423.730469\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"484.912109\" xlink:href=\"#DejaVuSans-107\"/>\n     <use x=\"539.197266\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"600.720703\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"664.099609\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"716.199219\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"747.986328\" xlink:href=\"#DejaVuSans-40\"/>\n     <use x=\"787\" xlink:href=\"#DejaVuSans-78\"/>\n     <use x=\"861.804688\" xlink:href=\"#DejaVuSans-61\"/>\n     <use x=\"945.59375\" xlink:href=\"#DejaVuSans-52\"/>\n     <use x=\"1009.216797\" xlink:href=\"#DejaVuSans-51\"/>\n     <use x=\"1072.839844\" xlink:href=\"#DejaVuSans-50\"/>\n     <use x=\"1136.462891\" xlink:href=\"#DejaVuSans-52\"/>\n     <use x=\"1200.085938\" xlink:href=\"#DejaVuSans-41\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"text_22\">\n   <!-- Histogram of successful predictions -->\n   <g transform=\"translate(105.484688 16.318125)scale(0.12 -0.12)\">\n    <defs>\n     <path d=\"M 9.8125 72.90625 \nL 19.671875 72.90625 \nL 19.671875 43.015625 \nL 55.515625 43.015625 \nL 55.515625 72.90625 \nL 65.375 72.90625 \nL 65.375 0 \nL 55.515625 0 \nL 55.515625 34.71875 \nL 19.671875 34.71875 \nL 19.671875 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-72\"/>\n     <path d=\"M 45.40625 27.984375 \nQ 45.40625 37.75 41.375 43.109375 \nQ 37.359375 48.484375 30.078125 48.484375 \nQ 22.859375 48.484375 18.828125 43.109375 \nQ 14.796875 37.75 14.796875 27.984375 \nQ 14.796875 18.265625 18.828125 12.890625 \nQ 22.859375 7.515625 30.078125 7.515625 \nQ 37.359375 7.515625 41.375 12.890625 \nQ 45.40625 18.265625 45.40625 27.984375 \nz\nM 54.390625 6.78125 \nQ 54.390625 -7.171875 48.1875 -13.984375 \nQ 42 -20.796875 29.203125 -20.796875 \nQ 24.46875 -20.796875 20.265625 -20.09375 \nQ 16.0625 -19.390625 12.109375 -17.921875 \nL 12.109375 -9.1875 \nQ 16.0625 -11.328125 19.921875 -12.34375 \nQ 23.78125 -13.375 27.78125 -13.375 \nQ 36.625 -13.375 41.015625 -8.765625 \nQ 45.40625 -4.15625 45.40625 5.171875 \nL 45.40625 9.625 \nQ 42.625 4.78125 38.28125 2.390625 \nQ 33.9375 0 27.875 0 \nQ 17.828125 0 11.671875 7.65625 \nQ 5.515625 15.328125 5.515625 27.984375 \nQ 5.515625 40.671875 11.671875 48.328125 \nQ 17.828125 56 27.875 56 \nQ 33.9375 56 38.28125 53.609375 \nQ 42.625 51.21875 45.40625 46.390625 \nL 45.40625 54.6875 \nL 54.390625 54.6875 \nz\n\" id=\"DejaVuSans-103\"/>\n     <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n     <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n     <path d=\"M 52 44.1875 \nQ 55.375 50.25 60.0625 53.125 \nQ 64.75 56 71.09375 56 \nQ 79.640625 56 84.28125 50.015625 \nQ 88.921875 44.046875 88.921875 33.015625 \nL 88.921875 0 \nL 79.890625 0 \nL 79.890625 32.71875 \nQ 79.890625 40.578125 77.09375 44.375 \nQ 74.3125 48.1875 68.609375 48.1875 \nQ 61.625 48.1875 57.5625 43.546875 \nQ 53.515625 38.921875 53.515625 30.90625 \nL 53.515625 0 \nL 44.484375 0 \nL 44.484375 32.71875 \nQ 44.484375 40.625 41.703125 44.40625 \nQ 38.921875 48.1875 33.109375 48.1875 \nQ 26.21875 48.1875 22.15625 43.53125 \nQ 18.109375 38.875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.1875 51.21875 25.484375 53.609375 \nQ 29.78125 56 35.6875 56 \nQ 41.65625 56 45.828125 52.96875 \nQ 50 49.953125 52 44.1875 \nz\n\" id=\"DejaVuSans-109\"/>\n     <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n     <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n    </defs>\n    <use xlink:href=\"#DejaVuSans-72\"/>\n    <use x=\"75.195312\" xlink:href=\"#DejaVuSans-105\"/>\n    <use x=\"102.978516\" xlink:href=\"#DejaVuSans-115\"/>\n    <use x=\"155.078125\" xlink:href=\"#DejaVuSans-116\"/>\n    <use x=\"194.287109\" xlink:href=\"#DejaVuSans-111\"/>\n    <use x=\"255.46875\" xlink:href=\"#DejaVuSans-103\"/>\n    <use x=\"318.945312\" xlink:href=\"#DejaVuSans-114\"/>\n    <use x=\"360.058594\" xlink:href=\"#DejaVuSans-97\"/>\n    <use x=\"421.337891\" xlink:href=\"#DejaVuSans-109\"/>\n    <use x=\"518.75\" xlink:href=\"#DejaVuSans-32\"/>\n    <use x=\"550.537109\" xlink:href=\"#DejaVuSans-111\"/>\n    <use x=\"611.71875\" xlink:href=\"#DejaVuSans-102\"/>\n    <use x=\"646.923828\" xlink:href=\"#DejaVuSans-32\"/>\n    <use x=\"678.710938\" xlink:href=\"#DejaVuSans-115\"/>\n    <use x=\"730.810547\" xlink:href=\"#DejaVuSans-117\"/>\n    <use x=\"794.189453\" xlink:href=\"#DejaVuSans-99\"/>\n    <use x=\"849.169922\" xlink:href=\"#DejaVuSans-99\"/>\n    <use x=\"904.150391\" xlink:href=\"#DejaVuSans-101\"/>\n    <use x=\"965.673828\" xlink:href=\"#DejaVuSans-115\"/>\n    <use x=\"1017.773438\" xlink:href=\"#DejaVuSans-115\"/>\n    <use x=\"1069.873047\" xlink:href=\"#DejaVuSans-102\"/>\n    <use x=\"1105.078125\" xlink:href=\"#DejaVuSans-117\"/>\n    <use x=\"1168.457031\" xlink:href=\"#DejaVuSans-108\"/>\n    <use x=\"1196.240234\" xlink:href=\"#DejaVuSans-32\"/>\n    <use x=\"1228.027344\" xlink:href=\"#DejaVuSans-112\"/>\n    <use x=\"1291.503906\" xlink:href=\"#DejaVuSans-114\"/>\n    <use x=\"1330.367188\" xlink:href=\"#DejaVuSans-101\"/>\n    <use x=\"1391.890625\" xlink:href=\"#DejaVuSans-100\"/>\n    <use x=\"1455.367188\" xlink:href=\"#DejaVuSans-105\"/>\n    <use x=\"1483.150391\" xlink:href=\"#DejaVuSans-99\"/>\n    <use x=\"1538.130859\" xlink:href=\"#DejaVuSans-116\"/>\n    <use x=\"1577.339844\" xlink:href=\"#DejaVuSans-105\"/>\n    <use x=\"1605.123047\" xlink:href=\"#DejaVuSans-111\"/>\n    <use x=\"1666.304688\" xlink:href=\"#DejaVuSans-110\"/>\n    <use x=\"1729.683594\" xlink:href=\"#DejaVuSans-115\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p50935c875b\">\n   <rect height=\"209.6\" width=\"157.425\" x=\"59.690625\" y=\"52.04\"/>\n  </clipPath>\n  <clipPath id=\"pc63afe51bc\">\n   <rect height=\"209.6\" width=\"157.425\" x=\"260.165625\" y=\"52.04\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.suptitle(f'Histogram of successful predictions')\n",
    "\n",
    "ax1.bar(x=['Found', 'Not found'], height=[P, N-P])\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_title(f'All tokens (N={N})')\n",
    "ax2.bar(x=['Found', 'Not found'], height=[P_u, N_u-P_u])\n",
    "ax2.set_title(f'Unique tokens (N={N_u})')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "source": [
    "Judging by the above statistics and the plotted graph there is a difference between the two approaches, but not as significant as in the case with accuracy. It is important to note however that in the in the accuracy measurement the criteria was stricter. Nevertheless it signals an important issue with most natural language processing problems: the training distribution and the test distribution (and the data found in real settings) differ and the prior do not encompass all information about the latter. It is sometimes because the test set containts out of vocabulary words or it could be due to the limited size of the training sample. Most often it is the prior and that is because language is simply non-stationary. Which means that language often changing, new words can appear or old ones can appear in new forms due to some transformation (especially in agglutinative languages).\n",
    "\n",
    "The only task left is to write the recovered tokens into an output."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_file = open('data/corrupted_tokens.txt', 'r')\n",
    "with open('data/recovered_tokens.txt', 'w') as output:\n",
    "    for line in corrupted_file:\n",
    "        t = line.strip().lower()\n",
    "        p = Y.get(t, t)\n",
    "        output.write(f'{p}\\n')\n",
    "corrupted_file.close()"
   ]
  },
  {
   "source": [
    "## 4. Summary\n",
    "\n",
    "In this challenge the task was to recover the original form of a set of corrupted tokens given a set of training tokens. I have given a description of the assumptions in the task and created a model that reflected those assumptions, but was also able to scale better than some other approaches used regularly. The modeling process reflected the observation that some tokens appeared much more frequently in the training data than other tokens. I have also made an attempt at measuring the efficiency of the submission using a holdout test set - splitted from the training data - and the recoveries on the corrupted data. I have showed different approaches in the efficiency measurement and highlighted how those can reflect different business goals. Finally I have written the recovered tokens into a text file."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}